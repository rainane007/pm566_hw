---
title: "pm566_HW3"
author: "Yuhong Hu"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(data.table)
library(skimr)
library(parallel)
library(RSQLite)
library(DBI)
library(knitr)
```

# HPC

## Q1

Rewrite the following R functions to make them faster. It is OK (and recommended) to take a look at Stackoverflow and Google

```{r, warning=FALSE}
# Total row sums
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}


fun1alt <- function(mat) {
  rowSums(mat)
}


# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}


fun2alt <- function(mat) {
  t(apply(mat, 1, cumsum)) }


# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
fun1comp <- microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), check = "equivalent"
)

print(fun1comp,unit = "relative")


# Test for the second
fun2comp <- microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), check = "equivalent"
)

print(fun2comp,unit = "relative")

```

The last argument, check = “equivalent”, is included to make sure that the functions return the same result.

## Q2 Make things run faster with parallel computing

The following function allows simulating PI

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

In order to get accurate estimates, we can run this function multiple times, with the following code:

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})

```

Rewrite the previous code using `parLapply()` to make it run faster. Make sure you set the seed using `clusterSetRNGStream()`:

```{r}
# YOUR CODE HERE
system.time({
  cl <- makePSOCKcluster(4L)   
  clusterSetRNGStream(cl, 1231)
  clusterExport(cl, c("sim_pi"),envir = environment())
  ans <- unlist(parLapply(cl,1:4000, sim_pi, n = 10000))
  print(mean(ans))
  stopCluster(cl)
})

```

# SQL

Setup a temporary database by running the following chunk

```{r}
# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

When you write a new chunk, remember to replace the r with sql, connection=con. Some of these questions will reqruire you to use an inner join. Read more about them here https://www.w3schools.com/sql/sql_join_inner.asp

## Q1

How many movies is there avaliable in each rating catagory.

```{sql,connection=con}
PRAGMA table_info(film)
```
The numbers of movies in each rating category were shown below.

```{sql,connection=con}
SELECT rating, COUNT(*) AS N
FROM film
GROUP BY rating
```

## Q2

The average replacement cost and rental rate for each rating category was shown below.

```{sql,connection=con}
SELECT rating,
       AVG(replacement_cost) AS avg_replacement_cost,
       AVG(rental_rate) AS avg_rental_rate
FROM film
GROUP BY rating
```

## Q3

Use table film_category together with film to find the how many films there are within each category ID

```{sql,connection=con}
PRAGMA table_info(film_category)
```

```{sql,connection=con}
SELECT category_id,COUNT(*) AS N
FROM film AS f
  INNER JOIN film_category AS fc
  ON f.film_id=fc.film_id
GROUP BY category_id
```
The result was the same if we only use table film_category.

```{sql,connection=con}
SELECT category_id,COUNT(*) AS N
FROM film_category 
GROUP BY category_id
```

## Q4

Incorporate table category into the answer to the previous question to find the name of the most popular category.

```{sql,connection=con}
SELECT fc.category_id,name,COUNT(*) AS N
FROM film_category AS fc
  INNER JOIN category AS c ON fc.category_id=c.category_id
  INNER JOIN film AS f ON f.film_id=fc.film_id
GROUP BY name
```



